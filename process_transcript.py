#!/usr/bin/env python3
from typing import Dict, List, Tuple, Optional
import re
import os
import json
import argparse
from dataclasses import dataclass
import sys
import pathlib

@dataclass
class EmotionData:
    arousal: float
    dominance: float
    valence: float
    
    def get_mood_emoji(self) -> str:
        if self.valence > 0.6:
            return "üòä"
        elif self.valence < 0.4:
            return "üòî"
        else:
            return "üòê"
            
    def get_trend_description(self) -> str:
        if self.valence > 0.6:
            return "–ü"  # –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–π
        elif self.valence < 0.4:
            return "–ù"  # –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π
        else:
            return "–ù—Ç"  # –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π
    
    def get_mood_full_name(self) -> str:
        if self.valence > 0.6:
            return "–ø–æ–∑–∏—Ç–∏–≤–Ω—ã–π"
        elif self.valence < 0.4:
            return "–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π"
        else:
            return "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π"
    
    def get_trend_direction(self, prev_emotion: Optional['EmotionData'] = None) -> Dict[str, str]:
        if prev_emotion is None:
            return {"arousal": "", "dominance": "", "valence": ""}
        
        directions = {}
        directions["arousal"] = "‚Üí" if abs(self.arousal - prev_emotion.arousal) < 0.05 else ("‚Üë" if self.arousal > prev_emotion.arousal else "‚Üì")
        directions["dominance"] = "‚Üí" if abs(self.dominance - prev_emotion.dominance) < 0.05 else ("‚Üë" if self.dominance > prev_emotion.dominance else "‚Üì")
        directions["valence"] = "‚Üí" if abs(self.valence - prev_emotion.valence) < 0.05 else ("‚Üë" if self.valence > prev_emotion.valence else "‚Üì")
        
        return directions


@dataclass
class TranscriptSegment:
    start_time: str
    end_time: str
    speaker: int
    emotion: EmotionData
    text: str
    
    def to_llm_json(self, extreme_compact: bool = True) -> str:
        """–§–æ—Ä–º–∞—Ç JSON –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ LLM-–º–æ–¥–µ–ª—è–º–∏
        
        Args:
            extreme_compact: –ï—Å–ª–∏ True, –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Å–æ–∫—Ä–∞—Ç–∏—Ç –¥–∞–Ω–Ω—ã–µ
        """
        # –£—Ä–æ–≤–µ–Ω—å –æ–∫—Ä—É–≥–ª–µ–Ω–∏—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞ —Å–∂–∞—Ç–∏—è
        precision = 1 if extreme_compact else 2
            
        segment_dict = {
            "t": f"{self.start_time}-{self.end_time}",
            "s": self.speaker,
            "e": {
                "a": round(self.emotion.arousal, precision),
                "d": round(self.emotion.dominance, precision),
                "v": round(self.emotion.valence, precision)
            },
            "tx": self.text
        }
        return json.dumps(segment_dict, ensure_ascii=False)
    
    def to_human_readable(self, prev_segment: Optional['TranscriptSegment'] = None, max_line_length: int = 100, include_timestamps: bool = True) -> str:
        """–§–æ—Ä–º–∞—Ç –¥–ª—è –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è —á–µ–ª–æ–≤–µ–∫–æ–º"""
        trend = self.emotion.get_trend_description()
        emoji = self.emotion.get_mood_emoji()
        
        if prev_segment is not None:
            prev_trend = prev_segment.emotion.get_trend_description()
            if prev_trend != trend:
                trend_text = f"{prev_trend}‚Üí{trend}"
            else:
                trend_text = trend
        else:
            trend_text = trend
            
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ—Ñ–∏–∫—Å–∞ —Å/–±–µ–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫
        if include_timestamps:
            prefix = f"[{self.start_time}‚Üí{self.end_time}] –°{self.speaker} {emoji} [{trend_text}]: "
        else:
            prefix = f"–°{self.speaker} {emoji} [{trend_text}]: "
        
        # –í–º–µ—Å—Ç–æ –æ–±—Ä–µ–∑–∫–∏ —Ç–µ–∫—Å—Ç–∞ –¥–µ–ª–∞–µ–º –ø–µ—Ä–µ–Ω–æ—Å –Ω–∞ –Ω–æ–≤—É—é —Å—Ç—Ä–æ–∫—É
        if len(prefix + self.text) > max_line_length:
            prefix_length = len(prefix)
            
            # –°–æ–∑–¥–∞–µ–º –æ—Ç—Å—Ç—É–ø –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö —Å—Ç—Ä–æ–∫
            indent = " " * prefix_length
            
            # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —Å–ª–æ–≤–∞
            words = self.text.split()
            
            lines = []
            current_line = prefix
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª–æ–≤–∞, —Å–æ–∑–¥–∞–≤–∞—è –Ω–æ–≤—É—é —Å—Ç—Ä–æ–∫—É –ø—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ max_line_length
            for word in words:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —É–º–µ—Å—Ç–∏—Ç—Å—è –ª–∏ —Å–ª–æ–≤–æ –≤ —Ç–µ–∫—É—â—É—é —Å—Ç—Ä–æ–∫—É
                if len(current_line + word) + 1 <= max_line_length:  # +1 –¥–ª—è –ø—Ä–æ–±–µ–ª–∞
                    if current_line == prefix:
                        current_line += word
                    else:
                        current_line += " " + word
                else:
                    # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –Ω–µ –ø—É—Å—Ç–∞—è, –¥–æ–±–∞–≤–ª—è–µ–º –µ–µ –≤ —Å–ø–∏—Å–æ–∫
                    if current_line != prefix and current_line != indent:
                        lines.append(current_line)
                    
                    # –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—É—é —Å—Ç—Ä–æ–∫—É —Å –æ—Ç—Å—Ç—É–ø–æ–º
                    current_line = indent + word
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–æ–∫—É
            if current_line != prefix and current_line != indent:
                lines.append(current_line)
                
            return "\n".join(lines)
        else:
            return prefix + self.text


def parse_transcript(input_file: str) -> List[TranscriptSegment]:
    """–ü–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞"""
    segments = []
    # –®–∞–±–ª–æ–Ω –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∞ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏ –∏ —ç–º–æ—Ü–∏—è–º–∏
    pattern_with_timestamps = r'\[(\d+:\d+) -> (\d+:\d+)\] (\d+) –°–ø–∏–∫–µ—Ä: \[(.*?)\] (.+)'
    # –®–∞–±–ª–æ–Ω –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∞ –±–µ–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ –∏ —ç–º–æ—Ü–∏–π
    pattern_simple = r'^(\d+) –°–ø–∏–∫–µ—Ä:(.*)$'
    
    with open(input_file, 'r', encoding='utf-8') as f:
        lines = f.readlines()
        
    # –ü—Ä–æ–±—É–µ–º —Ñ–æ—Ä–º–∞—Ç —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏
    for line in lines:
        match = re.match(pattern_with_timestamps, line)
        if match:
            start_time, end_time, speaker, emotion_text, text = match.groups()
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ —ç–º–æ—Ü–∏–π
            emotion_data = {"arousal": 0.5, "dominance": 0.5, "valence": 0.5}
            
            if "—ç–Ω—Ç—É–∑–∏–∞–∑–º" in emotion_text.lower():
                # –§–æ—Ä–º–∞—Ç [—ç–Ω—Ç—É–∑–∏–∞–∑–º (100.0%)]
                enthusiasm_match = re.search(r'\((\d+\.\d+)%\)', emotion_text)
                if enthusiasm_match:
                    try:
                        enthusiasm = float(enthusiasm_match.group(1)) / 100.0
                        emotion_data = {"arousal": 0.5, "dominance": 0.5, "valence": enthusiasm}
                    except ValueError:
                        pass
            else:
                # –§–æ—Ä–º–∞—Ç [A:0.51, D:0.54, V:0.65]
                a_match = re.search(r'A:([\d.]+)', emotion_text)
                d_match = re.search(r'D:([\d.]+)', emotion_text)
                v_match = re.search(r'V:([\d.]+)', emotion_text)
                
                if a_match and d_match and v_match:
                    try:
                        emotion_data = {
                            "arousal": float(a_match.group(1)),
                            "dominance": float(d_match.group(1)),
                            "valence": float(v_match.group(1))
                        }
                    except ValueError:
                        pass
            
            emotion = EmotionData(
                arousal=emotion_data["arousal"],
                dominance=emotion_data["dominance"],
                valence=emotion_data["valence"]
            )
            
            segment = TranscriptSegment(
                start_time=start_time,
                end_time=end_time,
                speaker=int(speaker),
                emotion=emotion,
                text=text.strip()
            )
            segments.append(segment)
    
    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Å–µ–≥–º–µ–Ω—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏, –ø—Ä–æ–±—É–µ–º –ø—Ä–æ—Å—Ç–æ–π —Ñ–æ—Ä–º–∞—Ç
    if not segments:
        current_speaker = None
        current_text = []
        segment_count = 0
        
        for line_num, line in enumerate(lines):
            simple_match = re.match(pattern_simple, line)
            
            if simple_match:
                # –ï—Å–ª–∏ —É –Ω–∞—Å –µ—Å—Ç—å –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –µ–≥–æ –∫–∞–∫ —Å–µ–≥–º–µ–Ω—Ç
                if current_speaker is not None and current_text:
                    # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Å–µ–≥–º–µ–Ω—Ç
                    end_minute = segment_count + 1
                    segment = TranscriptSegment(
                        start_time=f"{segment_count:02d}:00",
                        end_time=f"{end_minute:02d}:00",
                        speaker=current_speaker,
                        emotion=EmotionData(arousal=0.5, dominance=0.5, valence=0.5),
                        text=" ".join(current_text).strip()
                    )
                    segments.append(segment)
                    segment_count += 1
                
                # –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—ã–π —Å–µ–≥–º–µ–Ω—Ç
                current_speaker = int(simple_match.group(1))
                current_text = [simple_match.group(2).strip()]
            elif current_speaker is not None:
                # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ç–µ–∫—É—â–∏–π —Å–µ–≥–º–µ–Ω—Ç
                current_text.append(line.strip())
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–µ–≥–º–µ–Ω—Ç, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
        if current_speaker is not None and current_text:
            end_minute = segment_count + 1
            segment = TranscriptSegment(
                start_time=f"{segment_count:02d}:00",
                end_time=f"{end_minute:02d}:00",
                speaker=current_speaker,
                emotion=EmotionData(arousal=0.5, dominance=0.5, valence=0.5),
                text=" ".join(current_text).strip()
            )
            segments.append(segment)
                
    if not segments:
        print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –í —Ñ–∞–π–ª–µ {input_file} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞.")
    
    return segments


def merge_similar_segments(segments: List[TranscriptSegment]) -> List[TranscriptSegment]:
    """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –ø–æ–¥—Ä—è–¥ –∏–¥—É—â–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã –æ–¥–Ω–æ–≥–æ —Å–ø–∏–∫–µ—Ä–∞ —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ–º"""
    if not segments:
        return []
        
    merged_segments = []
    current_group = [segments[0]]
    
    for i in range(1, len(segments)):
        current = segments[i]
        prev = segments[i-1]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–≤–ø–∞–¥–∞–µ—Ç –ª–∏ —Å–ø–∏–∫–µ—Ä –∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ
        if (current.speaker == prev.speaker and 
            current.emotion.get_trend_description() == prev.emotion.get_trend_description()):
            current_group.append(current)
        else:
            # –ó–∞–≤–µ—Ä—à–∞–µ–º —Ç–µ–∫—É—â—É—é –≥—Ä—É–ø–ø—É
            if len(current_group) == 1:
                merged_segments.append(current_group[0])
            else:
                start_time = current_group[0].start_time
                end_time = current_group[-1].end_time
                merged_text = " ".join(s.text for s in current_group)
                
                merged_segment = TranscriptSegment(
                    start_time=start_time,
                    end_time=end_time,
                    speaker=current_group[0].speaker,
                    emotion=current_group[0].emotion,
                    text=merged_text
                )
                merged_segments.append(merged_segment)
            
            # –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—É—é –≥—Ä—É–ø–ø—É
            current_group = [current]
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –≥—Ä—É–ø–ø—É
    if len(current_group) == 1:
        merged_segments.append(current_group[0])
    else:
        start_time = current_group[0].start_time
        end_time = current_group[-1].end_time
        merged_text = " ".join(s.text for s in current_group)
        
        merged_segment = TranscriptSegment(
            start_time=start_time,
            end_time=end_time,
            speaker=current_group[0].speaker,
            emotion=current_group[0].emotion,
            text=merged_text
        )
        merged_segments.append(merged_segment)
    
    return merged_segments


def process_transcript(input_file: str, max_line_length: int = 100, include_timestamps: bool = True, extreme_compact: bool = True) -> None:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –¥–≤—É—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
    
    Args:
        input_file: –ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É
        max_line_length: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Å—Ç—Ä–æ–∫–∏ –≤ —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
        include_timestamps: –í–∫–ª—é—á–∞—Ç—å –ª–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –≤ —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç
        extreme_compact: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Å–æ–∫—Ä–∞—Ç–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ JSON (–æ–∫—Ä—É–≥–ª–µ–Ω–∏–µ –¥–æ 1 –∑–Ω–∞–∫–∞)
    """
    segments = parse_transcript(input_file)
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –ø–æ—Ö–æ–∂–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã
    merged_segments = merge_similar_segments(segments)
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –∫–∞–∫ –∏–º—è –¥–ª—è –ø–∞–ø–∫–∏
    file_path = pathlib.Path(input_file)
    output_dir_name = file_path.stem
    output_dir = os.path.join("output", output_dir_name)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    os.makedirs(output_dir, exist_ok=True)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –¥–ª—è LLM
    llm_output_path = os.path.join(output_dir, "transcript_llm.json")
    with open(llm_output_path, 'w', encoding='utf-8') as f:
        # –î–æ–±–∞–≤–ª—è–µ–º –ª–µ–≥–µ–Ω–¥—É –≤ –Ω–∞—á–∞–ª–æ —Ñ–∞–π–ª–∞
        legend = {
            "_legend": {
                "t": "time (start-end)",
                "s": "speaker number",
                "e": {
                    "a": "arousal (0-1)",
                    "d": "dominance (0-1)",
                    "v": "valence (0-1)"
                },
                "tx": "text content"
            }
        }
        
        f.write("[\n")
        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –ª–µ–≥–µ–Ω–¥—É –∫–∞–∫ –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç –º–∞—Å—Å–∏–≤–∞
        f.write("  " + json.dumps(legend, ensure_ascii=False) + ",\n")
        
        for i, segment in enumerate(segments):  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã –¥–ª—è LLM
            f.write("  " + segment.to_llm_json(extreme_compact))
            if i < len(segments) - 1:
                f.write(",")
            f.write("\n")
        f.write("]\n")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –¥–ª—è —á–µ–ª–æ–≤–µ–∫–∞
    human_output_path = os.path.join(output_dir, "transcript_human.txt")
    with open(human_output_path, 'w', encoding='utf-8') as f:
        # –î–æ–±–∞–≤–ª—è–µ–º –ª–µ–≥–µ–Ω–¥—É
        f.write("# –õ–µ–≥–µ–Ω–¥–∞:\n")
        f.write("# –° - –°–ø–∏–∫–µ—Ä\n")
        f.write("# –ü - –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–π\n")
        f.write("# –ù - –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π\n")
        f.write("# –ù—Ç - –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π\n")
        f.write("# üòä - –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–π\n")
        f.write("# üòê - –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π\n")
        f.write("# üòî - –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π\n")
        f.write("#\n")
        f.write("# –ü–æ—è—Å–Ω–µ–Ω–∏–µ –∫ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏:\n")
        f.write("# –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç —É–ø—Ä–æ—â–µ–Ω–Ω—ã—Ö –±—É–∫–≤–µ–Ω–Ω—ã—Ö –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏–π (–ü/–ù/–ù—Ç), –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —Ç–æ–ª—å–∫–æ –≤–∞–ª–µ–Ω—Ç–Ω–æ—Å—Ç—å\n")
        f.write("# (–ø–æ–∑–∏—Ç–∏–≤–Ω–æ—Å—Ç—å/–Ω–µ–≥–∞—Ç–∏–≤–Ω–æ—Å—Ç—å), –ø–æ–ª–Ω–∞—è AVD-–º–æ–¥–µ–ª—å —É—á–∏—Ç—ã–≤–∞–µ—Ç —Ç—Ä–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞:\n")
        f.write("#   A (Arousal) - –≤–æ–∑–±—É–∂–¥–µ–Ω–∏–µ/–∞–∫—Ç–∏–≤–∞—Ü–∏—è —ç–º–æ—Ü–∏–∏ (0 - —Å–ø–æ–∫–æ–π–Ω—ã–π, 1 - –≤–æ–∑–±—É–∂–¥–µ–Ω–Ω—ã–π)\n")
        f.write("#   V (Valence) - –≤–∞–ª–µ–Ω—Ç–Ω–æ—Å—Ç—å/–∑–Ω–∞–∫ —ç–º–æ—Ü–∏–∏ (0 - –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π, 1 - –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–π)\n")
        f.write("#   D (Dominance) - –¥–æ–º–∏–Ω–∞–Ω—Ç–Ω–æ—Å—Ç—å/–∫–æ–Ω—Ç—Ä–æ–ª—å (0 - –ø–æ–¥—á–∏–Ω–µ–Ω–Ω—ã–π, 1 - –¥–æ–º–∏–Ω–∏—Ä—É—é—â–∏–π)\n")
        f.write("# –≠–º–æ–¥–∑–∏ –∏ –±—É–∫–≤—ã –æ—Ç—Ä–∞–∂–∞—é—Ç —Ç–æ–ª—å–∫–æ –≤–∞–ª–µ–Ω—Ç–Ω–æ—Å—Ç—å (V), –≤ —Ç–æ –≤—Ä–µ–º—è –∫–∞–∫ –ø–æ–ª–Ω–∞—è –∫–∞—Ä—Ç–∏–Ω–∞ —ç–º–æ—Ü–∏–π\n")
        f.write("# –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –≤ —Ñ–∞–π–ª–µ transcript_llm.json —Å–æ –≤—Å–µ–º–∏ —Ç—Ä–µ–º—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ AVD.\n")
        f.write("\n")
        
        prev_segment = None
        for segment in merged_segments:
            f.write(segment.to_human_readable(prev_segment, max_line_length, include_timestamps) + "\n")
            prev_segment = segment

    print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫–µ {output_dir}")


def parse_args():
    parser = argparse.ArgumentParser(description='–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã')
    parser.add_argument('input_file', nargs='?', default="output/test_transcript.txt",
                       help='–ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞')
    parser.add_argument('--no-timestamps', action='store_true',
                       help='–ù–µ –≤–∫–ª—é—á–∞—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∏')
    parser.add_argument('--max-line-length', type=int, default=100,
                       help='–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Å—Ç—Ä–æ–∫–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∏—Ä—É—é—â–µ–º —Ñ–∞–π–ª–µ')
    parser.add_argument('--no-extreme-compact', action='store_true',
                       help='–û—Ç–∫–ª—é—á–∏—Ç—å —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ–µ —Å–∂–∞—Ç–∏–µ –¥–∞–Ω–Ω—ã—Ö (–±–æ–ª—å—à–µ —Ü–∏—Ñ—Ä –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π)')
    return parser.parse_args()


if __name__ == "__main__":
    args = parse_args()
    
    if not os.path.exists(args.input_file):
        print(f"–û—à–∏–±–∫–∞: —Ñ–∞–π–ª {args.input_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
    else:
        process_transcript(
            args.input_file, 
            args.max_line_length, 
            not args.no_timestamps,
            not args.no_extreme_compact
        ) 