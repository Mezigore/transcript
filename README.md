# Система транскрипции и анализа эмоций

Инструмент для транскрипции аудио/видео файлов с распознаванием эмоций, диаризацией говорящих и дополнительной аналитикой.

## Возможности системы

- **Транскрипция речи** - преобразование речи в текст с использованием Whisper Large-v3-Turbo
- **Диаризация** - определение кто и когда говорит
- **Анализ эмоций** - два режима определения эмоциональной окраски речи
- **Обработка аудио** - улучшение качества звука для Zoom/Meet звонков
- **Интеллектуальная постобработка** - создание JSON для LLM и человеко-читаемых форматов

## Быстрый запуск

### Основные команды

```bash
# Базовая обработка одного файла с анализом эмоций через wav2vec
python run.py --emotion-engine wav2vec

# Обработка с улучшенной постобработкой (создает JSON для LLM и человеко-читаемые форматы)
python run.py --emotion-engine wav2vec --post-process

# Обработка без временных меток в результатах постобработки
python run.py --emotion-engine wav2vec --post-process --no-timestamps

# Использование wavlm вместо wav2vec для анализа эмоций
python run.py --emotion-engine wavlm
```

## Описание команд

### Выбор движка анализа эмоций

- **wav2vec** - Более новый движок с трехмерной моделью эмоций (A/D/V):
  - A (Arousal) - возбуждение/активация (0-1)
  - D (Dominance) - доминантность/контроль (0-1)
  - V (Valence) - валентность/знак эмоции (0-1)
  
  Пример формата: `[A:0.51, D:0.54, V:0.65]`

- **wavlm** - Классический движок с категориальными эмоциями:
  - Определяет один доминирующий тип эмоции (энтузиазм, нейтральность и т.д.)
  - Указывает процент уверенности
  
  Пример формата: `[энтузиазм (98.5%)]`

### Параметры постобработки

При использовании `--post-process` создаются дополнительные форматы:

1. `transcript_human.txt` - удобный для чтения формат с эмодзи и указанием тренда эмоций
2. `transcript_llm.json` - JSON формат для анализа через LLM

Параметр `--no-timestamps` убирает временные метки из файлов постобработки, оставляя их только в основном транскрипте. Это делает вывод более компактным и удобным для чтения.

## Дополнительные команды

```bash
# Пропустить анализ эмоций (только транскрипция и диаризация)
python run.py --skip-emotions

# Запустить только постобработку существующих транскриптов
python process_all_transcripts.py

# Постобработка без временных меток
python process_all_transcripts.py --no-timestamps

# Обработка конкретного транскрипта
python process_transcript.py output/имя_файла_transcript.txt
```

## Режимы работы

Система предлагает два режима работы:
1. **Обработка одного файла** - интерактивный выбор файла для анализа
2. **Пакетная обработка** - автоматическая обработка всех файлов в директории `input/`

При запуске программа предложит выбрать режим работы:
```
Выберите режим:
1. Обработать один файл
2. Обработать все файлы (пакетная обработка)
```

## Результаты

После запуска команд результаты можно найти:

- Основные транскрипты: `output/*.txt`
- Файлы постобработки: `output/имя_файла_transcript/` (содержит файлы transcript_human.txt и transcript_llm.json)

## Структура проекта

```
transcript/
├── config.py             # Основной конфигурационный файл
├── run.py                # Главный файл запуска
├── process_transcript.py # Обработка одного транскрипта
├── process_all_transcripts.py # Обработка всех транскриптов
├── input/                # Директория с входными файлами
├── output/               # Директория с результатами
├── src/                  # Исходный код
│   ├── analysis/         # Модули анализа
│   │   ├── diarization.py      # Диаризация говорящих
│   │   ├── emotion.py          # Общий интерфейс анализа эмоций
│   │   ├── emotion_wav2vec.py  # Реализация wav2vec для эмоций (A/D/V)
│   │   ├── emo_recognizer.py   # Классическое распознавание эмоций (wavlm)
│   │   └── transcription.py    # Транскрипция речи
│   ├── audio/            # Модули обработки аудио
│   │   ├── audio_extractor.py  # Извлечение аудио из медиа
│   │   ├── audio_processor.py  # Обработка аудио
│   │   └── audio_pipeline.py   # Конвейер обработки аудио
│   ├── cli/              # Интерфейс командной строки
│   ├── pipelines/        # Конвейеры обработки
│   └── utils/            # Вспомогательные функции
```

### Аудио-модули

Система обработки аудио состоит из трех основных компонентов:

- **audio_extractor.py** - Базовое извлечение аудио из медиа-файлов без обработки
- **audio_processor.py** - Обработка аудио с оптимизированными фильтрами для Zoom-звонков
- **audio_pipeline.py** - Объединение извлечения и обработки в единый конвейер

Для обработки Zoom-звонков используются специальные FFmpeg-фильтры с улучшенным шумоподавлением и нормализацией громкости.

## Настройка параметров

Все настройки системы хранятся в файле `config.py`. Вы можете изменить:

- **TRANSCRIPTION** - параметры транскрипции Whisper
- **DIARIZATION** - настройки диаризации говорящих
- **AUDIO_PREPROCESSOR** - параметры предобработки аудио
- **OUTPUT_FORMAT** - формат вывода результатов

## Требования

Для работы необходимы следующие библиотеки:
- whisper/mlx-whisper (в зависимости от платформы)
- transformers 
- torch/torchaudio
- pyannote.audio (для диаризации)
- ffmpeg-python (обработка аудио)
- webrtcvad (улучшенная сегментация)
- numpy
- huggingface-hub
- и другие зависимости указанные в файлах requirements.txt и requirements-mac.txt

### Установка зависимостей

```bash
# Для Linux/Windows
pip install -r requirements.txt

# Для MacOS (с поддержкой Apple Silicon и MLX)
pip install -r requirements-mac.txt
```

## Рекомендации по использованию

1. Поместите аудио/видео файлы в директорию `input/`
2. Запустите команду `python run.py --emotion-engine wav2vec --post-process`
3. Готовые транскрипты будут доступны в директории `output/`

Для достижения наилучших результатов рекомендуется:
- Использовать аудио с хорошим качеством записи
- При обработке записей Zoom/Meet включать оптимизацию через параметры в config.py
- Для больших файлов рекомендуется использовать режим обработки без анализа эмоций (`--skip-emotions`) 